{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc13332",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add package to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root / 'src') not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / 'src'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321e09e",
   "metadata": {},
   "source": [
    "## 2. Memory Monitoring Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f81d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.13 GB\n"
     ]
    }
   ],
   "source": [
    "def get_memory_usage():\n",
    "    \"\"\"Get current process memory usage in GB.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / 1024**3  # Convert to GB\n",
    "\n",
    "def print_memory_stats(label):\n",
    "    \"\"\"Print current memory usage with a label.\"\"\"\n",
    "    mem_gb = get_memory_usage()\n",
    "    print(f\"{label}: {mem_gb:.2f} GB\")\n",
    "    return mem_gb\n",
    "\n",
    "# Baseline memory\n",
    "baseline_mem = print_memory_stats(\"Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d1423",
   "metadata": {},
   "source": [
    "## 3. Define Fields to Extract\n",
    "\n",
    "Select essential fields for analysis to minimize memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a118dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will extract 11 fields: ['mstars_disk', 'mstars_bulge', 'mhhalo', 'type', 'x', 'y', 'z', 'sfr_disk', 'sfr_burst', 'zgas_disk', 'zcold']\n"
     ]
    }
   ],
   "source": [
    "# Essential fields for most analyses\n",
    "FIELDS = [\n",
    "    'mstars_disk',\n",
    "    'mstars_bulge', \n",
    "    'mhhalo',\n",
    "    'type',\n",
    "    'x',\n",
    "    'y', \n",
    "    'z',\n",
    "    'sfr_disk',\n",
    "    'sfr_burst',\n",
    "    'zgas_disk',\n",
    "    'zcold'\n",
    "]\n",
    "\n",
    "print(f\"Will extract {len(FIELDS)} fields: {FIELDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b3d112",
   "metadata": {},
   "source": [
    "## 4. Load Data from One Snapshot\n",
    "\n",
    "Start with a single snapshot to estimate memory requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674add05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /cosma5/data/durham/dc-hick2/Galform_Out/L800/gp14\n",
      "\n",
      "Loading snapshot: iz201\n",
      "Path: /cosma5/data/durham/dc-hick2/Galform_Out/L800/gp14/iz201\n",
      "Path exists: False\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/cosma5/data/durham/dc-hick2/Galform_Out/L800/gp14/iz201'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Load the snapshot\u001b[39;00m\n\u001b[1;32m     72\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 73\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_snapshot_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnapshot_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m load_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     76\u001b[0m after_load_mem \u001b[38;5;241m=\u001b[39m print_memory_stats(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter loading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36mload_snapshot_to_dataframe\u001b[0;34m(snapshot_path, fields, use_float32)\u001b[0m\n\u001b[1;32m     21\u001b[0m all_data \u001b[38;5;241m=\u001b[39m {field: [] \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over subvolumes\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m subvol_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m snapshot_path\u001b[38;5;241m.\u001b[39miterdir() \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m.\u001b[39mis_dir() \u001b[38;5;129;01mand\u001b[39;00m d\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mivol\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subvol_dir \u001b[38;5;129;01min\u001b[39;00m subvol_dirs:\n\u001b[1;32m     27\u001b[0m     gal_file \u001b[38;5;241m=\u001b[39m subvol_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgalaxies.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m all_data \u001b[38;5;241m=\u001b[39m {field: [] \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over subvolumes\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m subvol_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m snapshot_path\u001b[38;5;241m.\u001b[39miterdir() \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m.\u001b[39mis_dir() \u001b[38;5;129;01mand\u001b[39;00m d\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mivol\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subvol_dir \u001b[38;5;129;01min\u001b[39;00m subvol_dirs:\n\u001b[1;32m     27\u001b[0m     gal_file \u001b[38;5;241m=\u001b[39m subvol_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgalaxies.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1078\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;03m    result for the special paths '.' and '..'.\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1079\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m   1080\u001b[0m             \u001b[38;5;66;03m# Yielding a path object for these makes little sense\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/cosma5/data/durham/dc-hick2/Galform_Out/L800/gp14/iz201'"
     ]
    }
   ],
   "source": [
    "from galform_analysis.config import get_base_dir\n",
    "\n",
    "# Get base directory\n",
    "base_dir = get_base_dir()\n",
    "print(f\"Base directory: {base_dir}\")\n",
    "\n",
    "# Select a snapshot to analyze\n",
    "snapshot = 'iz201'  # Change this to your desired snapshot\n",
    "snapshot_path = base_dir / snapshot\n",
    "\n",
    "print(f\"\\nLoading snapshot: {snapshot}\")\n",
    "print(f\"Path: {snapshot_path}\")\n",
    "print(f\"Path exists: {snapshot_path.exists()}\")\n",
    "\n",
    "# Define function to load snapshot into DataFrame\n",
    "def load_snapshot_to_dataframe(snapshot_path, fields=None, use_float32=True):\n",
    "    \"\"\"Load a GALFORM snapshot into a pandas DataFrame.\"\"\"\n",
    "    if fields is None:\n",
    "        fields = FIELDS\n",
    "    \n",
    "    all_data = {field: [] for field in fields}\n",
    "    \n",
    "    # Iterate over subvolumes\n",
    "    subvol_dirs = sorted([d for d in snapshot_path.iterdir() if d.is_dir() and d.name.startswith('ivol')])\n",
    "    \n",
    "    for subvol_dir in subvol_dirs:\n",
    "        gal_file = subvol_dir / 'galaxies.hdf5'\n",
    "        if not gal_file.exists():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with h5py.File(gal_file, 'r') as f:\n",
    "                # Check completion flag\n",
    "                if 'Output001' not in f:\n",
    "                    continue\n",
    "                output_group = f['Output001']\n",
    "                \n",
    "                # Check if there are any galaxies\n",
    "                first_field = fields[0]\n",
    "                if first_field not in output_group:\n",
    "                    continue\n",
    "                \n",
    "                n_gal = len(output_group[first_field])\n",
    "                if n_gal == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Load all requested fields\n",
    "                for field in fields:\n",
    "                    if field in output_group:\n",
    "                        arr = output_group[field][:]\n",
    "                        if use_float32 and arr.dtype in [np.float64, np.float32]:\n",
    "                            arr = arr.astype(np.float32)\n",
    "                        all_data[field].append(arr)\n",
    "                    else:\n",
    "                        # Fill with NaN if field missing\n",
    "                        all_data[field].append(np.full(n_gal, np.nan))\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read {gal_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Concatenate all subvolumes\n",
    "    df_data = {}\n",
    "    for field in fields:\n",
    "        if len(all_data[field]) > 0:\n",
    "            df_data[field] = np.concatenate(all_data[field])\n",
    "        else:\n",
    "            df_data[field] = np.array([])\n",
    "    \n",
    "    return pd.DataFrame(df_data)\n",
    "\n",
    "# Load the snapshot\n",
    "start_time = time.time()\n",
    "df = load_snapshot_to_dataframe(snapshot_path)\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "after_load_mem = print_memory_stats(\"After loading\")\n",
    "\n",
    "print(f\"\\nLoaded {len(df):,} galaxies in {load_time:.2f} seconds\")\n",
    "print(f\"Memory usage: {after_load_mem:.2f} GB\")\n",
    "print(f\"Memory increase: {after_load_mem - baseline_mem:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c3dcb",
   "metadata": {},
   "source": [
    "## 5. Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "Series([], dtype: object)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data types\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc4f25",
   "metadata": {},
   "source": [
    "## 6. Compute Derived Quantities\n",
    "\n",
    "Add useful derived fields like total stellar mass and SFR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a91e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After computing derived quantities: 0.20 GB\n",
      "Memory increase from derived fields: 0.00 GB\n",
      "\n",
      "Updated DataFrame shape: (0, 0)\n",
      "Columns: []\n"
     ]
    }
   ],
   "source": [
    "# Compute total stellar mass\n",
    "if 'mstars_disk' in df.columns and 'mstars_bulge' in df.columns:\n",
    "    df['mstar'] = df['mstars_disk'] + df['mstars_bulge']\n",
    "\n",
    "# Compute total SFR\n",
    "if 'sfr_disk' in df.columns and 'sfr_burst' in df.columns:\n",
    "    df['sfr'] = df['sfr_disk'] + df['sfr_burst']\n",
    "\n",
    "# Compute sSFR (specific star formation rate)\n",
    "if 'sfr' in df.columns and 'mstar' in df.columns:\n",
    "    df['ssfr'] = df['sfr'] / df['mstar']\n",
    "    df['ssfr'] = df['ssfr'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "after_derived_mem = print_memory_stats(\"After computing derived quantities\")\n",
    "print(f\"Memory increase from derived fields: {after_derived_mem - after_load_mem:.2f} GB\")\n",
    "\n",
    "print(f\"\\nUpdated DataFrame shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80be00b",
   "metadata": {},
   "source": [
    "## 7. Quick Analysis Test\n",
    "\n",
    "Test that we can efficiently analyze the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac75a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Warning: DataFrame is empty! No data was loaded.\n",
      "This could mean:\n",
      "  - The snapshot directory doesn't exist\n",
      "  - No subvolumes have CompletionFlag=1\n",
      "  - There was an error reading the HDF5 files\n"
     ]
    }
   ],
   "source": [
    "# Check if DataFrame has data\n",
    "if len(df) == 0:\n",
    "    print(\"⚠ Warning: DataFrame is empty! No data was loaded.\")\n",
    "    print(\"This could mean:\")\n",
    "    print(\"  - The snapshot directory doesn't exist\")\n",
    "    print(\"  - No subvolumes have CompletionFlag=1\")\n",
    "    print(\"  - There was an error reading the HDF5 files\")\n",
    "elif 'mstar' not in df.columns:\n",
    "    print(\"⚠ Warning: 'mstar' column not found!\")\n",
    "    print(\"Available columns:\", list(df.columns))\n",
    "    print(\"Make sure to run cell 13 (Compute Derived Quantities) first.\")\n",
    "else:\n",
    "    # Filter for valid galaxies\n",
    "    valid = (df['mstar'] > 0) & np.isfinite(df['mstar'])\n",
    "    df_valid = df[valid]\n",
    "    \n",
    "    print(f\"Valid galaxies: {len(df_valid):,} / {len(df):,}\")\n",
    "    \n",
    "    # Quick histogram of stellar masses\n",
    "    if len(df_valid) > 0:\n",
    "        log_mstar = np.log10(df_valid['mstar'])\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(log_mstar, bins=50, alpha=0.7, edgecolor='black')\n",
    "        plt.xlabel(r'$\\log_{10}(M_*/M_\\odot)$')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(f'Stellar Mass Distribution ({snapshot})')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nStellar mass statistics:\")\n",
    "        print(f\"  Min: {log_mstar.min():.2f}\")\n",
    "        print(f\"  Max: {log_mstar.max():.2f}\")\n",
    "        print(f\"  Median: {log_mstar.median():.2f}\")\n",
    "    else:\n",
    "        print(\"No valid galaxies with mstar > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b08fd8",
   "metadata": {},
   "source": [
    "## 8. Estimate Full Dataset Memory\n",
    "\n",
    "Extrapolate memory requirements for all snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70448e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory per galaxy: inf KB\n",
      "\n",
      "Total snapshots found: 9\n",
      "\n",
      "Estimated total memory for all snapshots:\n",
      "  Galaxies per snapshot: 0\n",
      "  Total galaxies (all snapshots): 0\n",
      "  Estimated memory: nan GB\n",
      "\n",
      "Memory optimization tips:\n",
      "  1. Using float32 vs float64: ~50% savings\n",
      "  2. Selecting fewer fields: proportional savings\n",
      "  3. Loading per-snapshot: ~nan GB each\n",
      "\n",
      "Total snapshots found: 9\n",
      "\n",
      "Estimated total memory for all snapshots:\n",
      "  Galaxies per snapshot: 0\n",
      "  Total galaxies (all snapshots): 0\n",
      "  Estimated memory: nan GB\n",
      "\n",
      "Memory optimization tips:\n",
      "  1. Using float32 vs float64: ~50% savings\n",
      "  2. Selecting fewer fields: proportional savings\n",
      "  3. Loading per-snapshot: ~nan GB each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3510487/2668045648.py:2: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  mem_per_galaxy = df.memory_usage(deep=True).sum() / len(df)\n",
      "/tmp/ipykernel_3510487/2668045648.py:11: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  estimated_total_memory_gb = (mem_per_galaxy * estimated_total_galaxies) / 1024**3\n"
     ]
    }
   ],
   "source": [
    "# Memory per galaxy\n",
    "mem_per_galaxy = df.memory_usage(deep=True).sum() / len(df)\n",
    "print(f\"Memory per galaxy: {mem_per_galaxy / 1024:.2f} KB\")\n",
    "\n",
    "# Count total snapshots\n",
    "all_snapshots = sorted([d for d in base_dir.iterdir() if d.is_dir() and d.name.startswith('iz')])\n",
    "print(f\"\\nTotal snapshots found: {len(all_snapshots)}\")\n",
    "\n",
    "# Estimate for all snapshots (assuming similar galaxy counts)\n",
    "estimated_total_galaxies = len(df) * len(all_snapshots)\n",
    "estimated_total_memory_gb = (mem_per_galaxy * estimated_total_galaxies) / 1024**3\n",
    "\n",
    "print(\"\\nEstimated total memory for all snapshots:\")\n",
    "print(f\"  Galaxies per snapshot: {len(df):,}\")\n",
    "print(f\"  Total galaxies (all snapshots): {estimated_total_galaxies:,}\")\n",
    "print(f\"  Estimated memory: {estimated_total_memory_gb:.2f} GB\")\n",
    "\n",
    "# Memory optimization recommendations\n",
    "print(\"\\nMemory optimization tips:\")\n",
    "print(\"  1. Using float32 vs float64: ~50% savings\")\n",
    "print(\"  2. Selecting fewer fields: proportional savings\")\n",
    "print(f\"  3. Loading per-snapshot: ~{estimated_total_memory_gb / len(all_snapshots):.2f} GB each\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e8342",
   "metadata": {},
   "source": [
    "## 9. Performance Comparison\n",
    "\n",
    "Compare DataFrame approach vs. repeated HDF5 reads for a typical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance with DataFrame approach...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mstar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m mass_bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m8.0\u001b[39m, \u001b[38;5;241m12.5\u001b[39m, \u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m valid_mask \u001b[38;5;241m=\u001b[39m (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmstar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m np\u001b[38;5;241m.\u001b[39misfinite(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmstar\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m log_mstar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(df[valid_mask][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmstar\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m counts, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(log_mstar, bins\u001b[38;5;241m=\u001b[39mmass_bins)\n",
      "File \u001b[0;32m~/galform_analysis/.venv/lib64/python3.9/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/galform_analysis/.venv/lib64/python3.9/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mstar'"
     ]
    }
   ],
   "source": [
    "# Test: Compute mass function from DataFrame\n",
    "print(\"Testing performance with DataFrame approach...\")\n",
    "start = time.time()\n",
    "\n",
    "mass_bins = np.arange(8.0, 12.5, 0.2)\n",
    "valid_mask = (df['mstar'] > 0) & np.isfinite(df['mstar'])\n",
    "log_mstar = np.log10(df[valid_mask]['mstar'])\n",
    "counts, _ = np.histogram(log_mstar, bins=mass_bins)\n",
    "\n",
    "df_time = time.time() - start\n",
    "print(f\"DataFrame computation time: {df_time:.4f} seconds\")\n",
    "\n",
    "# Note: A full comparison would re-read HDF5 files, but we can estimate\n",
    "print(\"\\nDataFrame approach is ideal for:\")\n",
    "print(\"  - Multiple analyses on same data\")\n",
    "print(\"  - Interactive exploration\")\n",
    "print(\"  - Complex filtering/grouping operations\")\n",
    "print(\"\\nHDF5 approach is better for:\")\n",
    "print(\"  - Single-use analyses\")\n",
    "print(\"  - Memory-constrained environments\")\n",
    "print(\"  - Accessing only a few fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c147dd",
   "metadata": {},
   "source": [
    "## 10. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ed969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MEMORY USAGE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nSingle snapshot ({snapshot}):\")\n",
    "print(f\"  Galaxies: {len(df):,}\")\n",
    "print(f\"  Fields: {len(df.columns)}\")\n",
    "print(f\"  Memory: {df.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
    "print(f\"  Load time: {load_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nEstimated for all {len(all_snapshots)} snapshots:\")\n",
    "print(f\"  Total memory: {estimated_total_memory_gb:.2f} GB\")\n",
    "print(f\"  Per-snapshot approach: {estimated_total_memory_gb / len(all_snapshots):.2f} GB each\")\n",
    "\n",
    "print(\"\\nRecommendation:\")\n",
    "if estimated_total_memory_gb < 100:\n",
    "    print(\"  ✓ Loading all snapshots is FEASIBLE on HPC\")\n",
    "elif estimated_total_memory_gb < 500:\n",
    "    print(\"  ⚠ Loading all snapshots may work, but consider per-snapshot approach\")\n",
    "else:\n",
    "    print(\"  ✗ Loading all snapshots NOT recommended, use per-snapshot approach\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
